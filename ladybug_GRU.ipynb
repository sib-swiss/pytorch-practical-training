{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d5f7f8c-79b9-4e5b-a1b0-28185353c522",
   "metadata": {},
   "source": [
    "# Ladybug : predicting 2D trajectory with GRU\n",
    "\n",
    "This notebook is very inspired by the excellent [FIDLE](https://fidle.cnrs.fr/) course from CNRS (in french)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a8ffd-58f7-422f-b69b-9187bf8da046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict , Counter\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_model_summary as pms \n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dedbc0b-c978-4d2e-8f89-b197d5d1e2ae",
   "metadata": {},
   "source": [
    "## 1. data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54e7671-8ac5-4b12-998b-ed9817dfe128",
   "metadata": {},
   "source": [
    "### 1.1 generating ladybug trajectory data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93866e36-7854-4dee-845b-4391e0f9d1e3",
   "metadata": {},
   "source": [
    "For this simple example, we generate some artificial trajectory data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd094b-c905-4633-a7c6-0a7bec4ccc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from math import cos, sin\n",
    "\n",
    "def ladybug_init(s=122):\n",
    "    \n",
    "    if s>0 : random.seed(s)\n",
    "    ladybug_init.params_x = [ random.gauss(0.,1.) for u in range(8)]\n",
    "    ladybug_init.params_y = [ random.gauss(0.,1.) for u in range(8)]\n",
    "    \n",
    "def ladybug_move(t):\n",
    "\n",
    "    [ax1, ax2, ax3, ax4, kx1, kx2, kx3, kx4] = ladybug_init.params_x\n",
    "    [ay1, ay2, ay3, ay4, ky1, ky2, ky3, ky4] = ladybug_init.params_y\n",
    "    \n",
    "    x = ax1*sin(t*(kx1+20)) + ax2*cos(t*(kx2+10)) + ax3*sin(t*(kx3+5)) + ax4*cos(t*(kx4+5))\n",
    "    y = ay1*cos(t*(ky1+20)) + ay2*sin(t*(ky2+10)) + ay3*cos(t*(ky3+5)) + ay4*sin(t*(ky4+5)) \n",
    "\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bab827e-80ea-4aca-bcaf-69808167a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- About dataset\n",
    "#\n",
    "max_t        = 1000\n",
    "delta_t      = 0.003\n",
    "features_len = 2\n",
    "\n",
    "\n",
    "sequence_len = 20\n",
    "predict_len  = 5\n",
    "\n",
    "scale         = .2       # Percentage of dataset to be used (1=all)\n",
    "train_prop    = .8       # Percentage for train (the rest being for the valid)\n",
    "\n",
    "# ---- Get positions\n",
    "#\n",
    "ladybug_init(s=16)\n",
    "x,y = 0,0\n",
    "positions=[]\n",
    "for t in np.arange(0., max_t, delta_t):\n",
    "    x,y = ladybug_move(t)\n",
    "    positions.append([x,y])\n",
    "\n",
    "# ---- Build rescaled dataset\n",
    "#\n",
    "n = int( len(positions)*scale )\n",
    "dataset = np.array(positions[:n])\n",
    "\n",
    "k = int(len(dataset)*train_prop)\n",
    "x_train = dataset[:k]\n",
    "x_valid  = dataset[k:]\n",
    "\n",
    "# ---- Normalize\n",
    "#\n",
    "mean = x_train.mean()\n",
    "std  = x_train.std()\n",
    "x_train = (x_train - mean) / std\n",
    "x_valid  = (x_valid  - mean) / std\n",
    "\n",
    "print(\"Dataset generated.\")\n",
    "print(\"Train shape is : \", x_train.shape)\n",
    "print(\"Valid  shape is : \", x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c926e-921f-445a-9ea0-8378e97ce371",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting part of the trajectory.\n",
    "plt.plot( x_train[:500,0] , x_train[:500,1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74bc30a-88a9-48a2-b79c-0d074fd741ca",
   "metadata": {},
   "source": [
    "The goal will be to predict the next point in the trajectory given the previous 20 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a505c99d-fcf6-4dff-b061-68805f2f0261",
   "metadata": {},
   "outputs": [],
   "source": [
    "k1,k2 = sequence_len, 2\n",
    "i = random.randint(0,len(x_valid)-k1-k2)\n",
    "j = i+k1\n",
    "\n",
    "plt.plot( x_valid[i:j+k2,0] , x_valid[i:j+k2,1] , label = 'input' )\n",
    "plt.plot( x_valid[j:j+k2,0] , x_valid[j:j+k2,1] , label = 'objective' )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f28d665-98c2-4f74-8298-d92e71cc977a",
   "metadata": {},
   "source": [
    "### 1.2 prepare the sequences from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21f79a8-a044-4b78-b21b-dd814a27802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Create sequences and labels for train and valid\n",
    "xs_train, ys_train=[],[]\n",
    "\n",
    "# each sequence is the defined by its start point. \n",
    "# we use permutation to have random start points\n",
    "all_i = np.random.permutation( len(x_train) - sequence_len - 1 ) \n",
    "\n",
    "for i in all_i:\n",
    "    xs_train.append( x_train[ i : i+sequence_len ] )\n",
    "    ys_train.append( x_train[ i+sequence_len+1 ]   )\n",
    "    \n",
    "xs_valid, ys_valid=[],[]\n",
    "for i in range( len(x_valid) - sequence_len - 1):\n",
    "    xs_valid.append( x_valid[ i : i+sequence_len ] )\n",
    "    ys_valid.append( x_valid[ i+sequence_len+1 ]   )\n",
    "\n",
    "# ---- Convert to pytorch dataset\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor( np.array(xs_train, dtype='float16') ) ,\n",
    "                              torch.Tensor( np.array(ys_train, dtype='float16') ) ) \n",
    "valid_dataset = TensorDataset(torch.Tensor( np.array(xs_valid, dtype='float16') ) ,\n",
    "                              torch.Tensor( np.array(ys_valid, dtype='float16') ) ) \n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(train_dataset , batch_size = batch_size )\n",
    "valid_dataloader = DataLoader(valid_dataset , batch_size = batch_size )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1f5c03-909c-4c06-bb08-f0507704a429",
   "metadata": {},
   "source": [
    "## exercise\n",
    "\n",
    "### exercise 1 defining model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b10f86a-042c-464f-a6a5-1a5ee2dc96e0",
   "metadata": {},
   "source": [
    "We want a model that takes a sequence of ladybug positions (dimension: (number of timepoints,2) )\n",
    "and outputs the next position (dimension: 2 ).\n",
    "\n",
    " 1. Create a model using a GRU and a set of linear layers to predict the next ladybug prediction\n",
    " 2. train your model to optimize a Mean Squared Error loss (`nn.MSELoss()`)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afc3d36-1453-46dd-a039-b955c737f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ladybug_GRU(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self , input_dim = features_len, \n",
    "                         hidden_dim = 10 ,\n",
    "                         num_layers = 1 ,\n",
    "                         output_dim = 2 ):\n",
    "        super().__init__()\n",
    "        ...\n",
    "\n",
    "    def forward(self,x):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b93b12-c32f-4209-9e44-84ce85eb9aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use the following code to test your model:\n",
    "print(pms.summary(model, torch.zeros(3,10,2).to(device), show_input=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80d81f5-4e22-45df-9c45-1399a9311742",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use the following code to test your model:\n",
    "x, y = valid_dataset[:5] ## let's go with a batch of 5 samples\n",
    "\n",
    "with torch.no_grad(): ## disables tracking of gradient: prevent accidental training + speeds up computation\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = pred, y\n",
    "    print(f'Predicted : \\n\"{predicted}\"\\nActual: \\n\"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6376fc27-26dd-4d12-95d9-652bbe4bf599",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use the following code to test your model:\n",
    "loss = nn.MSELoss()\n",
    "loss(predicted,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc43976-7b7a-4af2-a48d-e2998fc5f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/GRU_ladybug.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b51ed-ac5f-4611-9614-3ac181db2ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pms.summary(model, torch.zeros(3,10,2).to(device), show_input=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a055424-71e6-4304-98b6-3efd064290db",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = valid_dataset[:5] ## let's go with a batch of 5 samples\n",
    "\n",
    "with torch.no_grad(): ## disables tracking of gradient: prevent accidental training + speeds up computation\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = pred, y\n",
    "    print(f'Predicted : \\n\"{predicted}\"\\nActual: \\n\"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdb3b17-b9c7-4ac6-8274-8b81973a6e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## usual helper funtions:\n",
    "def train(dataloader, model, loss_fn, optimizer, echo = True , echo_batch = False):\n",
    "    \n",
    "    size = len(dataloader.dataset) # how many batches do we have\n",
    "    model.train() #     Sets the module in training mode.\n",
    "    \n",
    "    ## we will keep prediction and target on the whole dataset\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader): # for each batch\n",
    "        X, y = X.to(device), y.to(device) # send the data to the GPU or whatever device you use for training\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)              # prediction for the model -> forward pass\n",
    "        loss = loss_fn(pred, y)      # loss function from these prediction\n",
    "        \n",
    "        loss.backward()              # backward propagation \n",
    "\n",
    "        optimizer.step()             \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if echo_batch:\n",
    "            current =  (batch + 1) * len(X)\n",
    "            print(f\"Train loss: {loss.item():>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "    if echo:\n",
    "        current =  (batch + 1) * len(X)\n",
    "        print(f\"Train loss: {loss.item():>7f}\")\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def valid(dataloader, model, loss_fn, echo = True):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval() #     Sets the module in evaluation mode\n",
    "        \n",
    "    valid_loss = 0\n",
    "    with torch.no_grad(): ## disables tracking of gradient: prevent accidental training + speeds up computation\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            valid_loss += loss_fn(pred, y).item()  ## accumulating the loss function over the batches\n",
    "            \n",
    "    valid_loss /= num_batches\n",
    "\n",
    "    if echo:\n",
    "        print(f\"\\tValid loss: {valid_loss:>8f}\")\n",
    "    ## return the average loss / batch\n",
    "    return  valid_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dd301d-3b8b-4193-bcab-c9cda479cb58",
   "metadata": {},
   "source": [
    "### exercise 2 training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd80e39-d3ee-4705-89f8-7c87ab5ce6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ladybug_GRU( features_len , 50, 2 ).to(device)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "## these parameters worked well for me in my tests, but you may have to adapt the learning rate:\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                       lr = 10**-3,\n",
    "                       weight_decay = 10**-2)\n",
    "\n",
    "\n",
    "## container to keep the scores across all epochs\n",
    "train_scores = []\n",
    "valid_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bf3f47-165d-4176-8992-8e9eec1d0a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(10): ## depending on your model, you may need as little as 5 epochs, or as much as 100...\n",
    "    train_scores.append( train(train_dataloader, \n",
    "                               model, \n",
    "                               loss, \n",
    "                               optimizer,\n",
    "                               echo = True,\n",
    "                               echo_batch = False \n",
    "                               )\n",
    "                         )\n",
    "    \n",
    "    \n",
    "    valid_scores.append( valid(valid_dataloader, \n",
    "                               model, \n",
    "                               loss , \n",
    "                               echo = True\n",
    "                              )\n",
    "                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68839f44-9030-4566-b526-6a8f1f928b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_scores,label='train')\n",
    "plt.plot(valid_scores,label='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0137b659-39c5-4433-a4f2-eca6f6e65fcd",
   "metadata": {},
   "source": [
    "## plotting a single prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7a760b-c61f-4c5c-b69a-9b6f8ad76374",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = valid_dataset[15]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(x.unsqueeze(0)).detach().squeeze()\n",
    "\n",
    "plt.plot( x[:,0] , x[:,1])\n",
    "plt.plot( [ x[-1,0], y[0]] , [x[-1,1], y[1]] , linestyle = '-' )\n",
    "plt.plot( [x[-1,0],y_pred[0]] , [x[-1,1], y_pred[1]] , linestyle = '--' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14c621d-2222-4232-926a-e202f79f584e",
   "metadata": {},
   "source": [
    "## prediction of multiple time steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e290ca2-dcf0-485c-8e1a-fd330b88bc5f",
   "metadata": {},
   "source": [
    "We are going to see how the model fares when we predict multiple time steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abfc511-a16e-4f06-810a-fd398f099ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_len = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cd8d2a-3ad8-4865-8b7b-58aa5a6e3642",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint( 0, len(x_valid) - sequence_len - pred_len )\n",
    "x = x_valid[ i : i+sequence_len ]\n",
    "y = x_valid[ i+sequence_len : i+sequence_len+pred_len ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ffe1ec-b060-48b7-9abd-8e091fe45e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    xt = torch.Tensor( x ).unsqueeze(0)\n",
    "    y_pred = model( xt ).detach()\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a02bd4b-0059-4875-84e4-c4c7158d2376",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended = torch.cat( ( xt, y_pred.unsqueeze(0) ) , 1 )\n",
    "extended.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b3b56-ec91-4166-a24a-574a9ddf508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multiple_timepoints(model, x , pred_len ):\n",
    "    xt = torch.Tensor( x ).unsqueeze(0)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for l in range( pred_len ) :\n",
    "            y_pred = model( xt ).detach()\n",
    "            xt = torch.cat( ( xt, y_pred.unsqueeze(0) ) , 1 )\n",
    "    \n",
    "    return xt[0,:pred_len,:].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8abea99-e788-453d-98e7-c91f4a5f30af",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_multiple_timepoints(model, x , pred_len )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7720f-bb1e-4ede-ac6b-e2150fd029ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint( 0, len(x_valid) - sequence_len - pred_len )\n",
    "x = x_valid[ i : i+sequence_len ]\n",
    "y = x_valid[ i+sequence_len : i+sequence_len+pred_len ]\n",
    "y_pred  = predict_multiple_timepoints(model, x , pred_len )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3376c3-8c86-40b8-8d31-e29b0b0f32a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding the last x point for plotting purpose\n",
    "xy = np.concat( ( x[[-1],:] , y ) )\n",
    "xypred = np.concat( ( x[[-1],:] , y_pred ) )\n",
    "\n",
    "plt.plot( x[:,0] , x[:,1])\n",
    "plt.plot( xy[:,0] , xy[:,1] , linestyle = '-' )\n",
    "plt.plot( xypred[:,0] , xypred[:,1] , linestyle = '--' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c6564e-a1ac-451a-bd9d-d0f208aa5595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
