{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2de400d0-6760-4bb8-bd46-a6346e76e270",
   "metadata": {},
   "source": [
    "# GRU example: Human Activity Recognition Using Smartphones\n",
    "\n",
    "We are going to play with the UCI's [Human Activity Recognition Using Smartphones](https://archive.ics.uci.edu/dataset/240/human+activity+recognition+using+smartphones) dataset.\n",
    "\n",
    "The experiments have been carried out with a group of volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. \n",
    "\n",
    "---\n",
    "\n",
    "For the purpose of this course, we have sampled this dataset to keep only 10% of the records. \n",
    "\n",
    "\n",
    "\n",
    "Citation:\n",
    "[A Public Domain Dataset for Human Activity Recognition using Smartphones](https://www.semanticscholar.org/paper/A-Public-Domain-Dataset-for-Human-Activity-using-Anguita-Ghio/83de43bc849ad3d9579ccf540e6fe566ef90a58e)\n",
    "By D. Anguita, A. Ghio, L. Oneto, X. Parra, Jorge Luis Reyes-Ortiz. 2013\n",
    "Published in The European Symposium on Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afaee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_model_summary as pms \n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from pytorchtools import EarlyStopping\n",
    "\n",
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439cc80f-aada-45b5-90d2-8ccf51797d58",
   "metadata": {},
   "source": [
    "For reference, here is the code we used to load and subset the original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d4fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"drsaeedmohsen/ucihar-dataset\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)\n",
    "\n",
    "# # 1. Load Inertial Signals\n",
    "# def load_signals(folder, subset):\n",
    "#     signals = []\n",
    "#     signal_names = [\n",
    "#         'body_acc_x_', 'body_acc_y_', 'body_acc_z_',\n",
    "#         'body_gyro_x_', 'body_gyro_y_', 'body_gyro_z_',\n",
    "#         'total_acc_x_', 'total_acc_y_', 'total_acc_z_'\n",
    "#     ]\n",
    "#     for name in signal_names:\n",
    "#         filename = os.path.join(folder, subset, 'Inertial Signals', name + subset + '.txt')\n",
    "#         data = np.loadtxt(filename)\n",
    "#         signals.append(data)\n",
    "#     # Stack signals: shape (samples, timesteps, features)\n",
    "#     return np.transpose(np.array(signals), (1, 2, 0))\n",
    "\n",
    "# def load_labels(folder, subset):\n",
    "#     filename = os.path.join(folder, subset, 'y_' + subset + '.txt')\n",
    "#     return np.loadtxt(filename).astype(int) - 1  # Classes start at 0\n",
    "\n",
    "# data_folder = 'data/UCI_HAR/'\n",
    "# X_train = load_signals(data_folder, 'train')\n",
    "# y_train = load_labels(data_folder, 'train')\n",
    "# X_test = load_signals(data_folder, 'test')\n",
    "# y_test = load_labels(data_folder, 'test')\n",
    "\n",
    "\n",
    "# # Assume X_train and y_train are NumPy arrays\n",
    "# fraction = 0.1  # 10%\n",
    "# subset_size = int(len(X_train) * fraction)\n",
    "\n",
    "# # Randomly select indices without replacement\n",
    "# indices = np.random.choice(len(X_train), subset_size, replace=False)\n",
    "\n",
    "# # Create smaller subsets\n",
    "# X_train_small = X_train[indices]\n",
    "# y_train_small = y_train[indices]\n",
    "\n",
    "# subset_size = int(len(X_test) * fraction)\n",
    "\n",
    "# # Randomly select indices without replacement\n",
    "# indices = np.random.choice(len(X_test), subset_size, replace=False)\n",
    "\n",
    "# X_test_small = X_test[indices]\n",
    "# y_test_small = y_test[indices]\n",
    "\n",
    "# X_train = X_train_small\n",
    "# y_train = y_train_small\n",
    "# X_test = X_test_small\n",
    "# y_test = y_test_small\n",
    "\n",
    "# print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")  # (7352, 128, 9)\n",
    "\n",
    "# np.save(\"data/UCI_HAR_subset/x_train.npy\" , X_train)\n",
    "# np.save(\"data/UCI_HAR_subset/x_valid.npy\" , X_test)\n",
    "# np.save(\"data/UCI_HAR_subset/y_train.npy\" , y_train)\n",
    "# np.save(\"data/UCI_HAR_subset/y_valid.npy\" , X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fa66a5-78d7-45c0-825c-f613c15a354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"data/UCI_HAR_subset/x_train.npy\")\n",
    "X_valid = np.load(\"data/UCI_HAR_subset/x_valid.npy\")\n",
    "y_train = np.load(\"data/UCI_HAR_subset/y_train.npy\")\n",
    "y_valid = np.load(\"data/UCI_HAR_subset/y_valid.npy\")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Valid shape: {X_valid.shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635b4862-aeaa-4548-b0c3-7cc5d1ebfa90",
   "metadata": {},
   "source": [
    "Each record consist in 128 time points measured for 9 features:\n",
    " - *body_acc_x/y/z*: The body acceleration signal obtained by subtracting the gravity from the total acceleration.\n",
    " - *body_gyro_x/y/z*: The angular velocity vector measured by the gyroscope for each window sample. The units are radians/second. \n",
    " - *total_acc_x/y/z*: The acceleration signal from the smartphone accelerometer X,Y and Z axis in standard gravity units 'g'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b182460-6afe-407d-a217-6c9547234113",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot( y_train )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5258c25-acfc-4a71-a8cf-79524de9d3b1",
   "metadata": {},
   "source": [
    "The target is:\n",
    " * 0 WALKING\n",
    " * 1 WALKING_UPSTAIRS\n",
    " * 2 WALKING_DOWNSTAIRS\n",
    " * 3 SITTING\n",
    " * 4 STANDING\n",
    " * 5 LAYING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967827f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building our loaders\n",
    "\n",
    "train_dataset = TensorDataset( torch.tensor( X_train, dtype=torch.float32) ,\n",
    "                            torch.tensor( y_train, dtype=torch.long) \n",
    "                            )\n",
    "valid_dataset = TensorDataset( torch.tensor( X_valid, dtype=torch.float32) ,\n",
    "                            torch.tensor( y_valid, dtype=torch.long) \n",
    "                            )\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54581d59-7a5e-4973-b7ce-fa3003b794d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU Model\n",
    "class HAR_GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(HAR_GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, num_classes) ## this could be as complex as we need it to be.\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # NB: the GRU could also take an additional input which would be the hidden state\n",
    "        #     of a previous RNN layer. Here by default it is a set of 0s\n",
    "        out, _ = self.gru(x) # output: GRU output , hidden state of last GRU layer\n",
    "        out = out[:, -1, :] ## we take the output of the last sequence element \n",
    "        return self.fc(out) ## and pass it to the dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccde52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HAR_GRU(input_size=9, hidden_size=32, num_layers=2, num_classes=6).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# --- 1) Prepare metric containers ---\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986d35cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Training Loop\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    ## \n",
    "    model.train()\n",
    "    train_loss, correct, total = 0, 0, 0\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == y).sum().item()\n",
    "            val_total += y.size(0)\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "\n",
    "# --- 2) Store metrics each epoch ---\n",
    "    train_losses.append(train_loss / total)\n",
    "    val_losses.append(val_loss / val_total)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e830276",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 3) Plot with Matplotlib ---\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs_range = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, train_losses, label='Train Loss', marker='o')\n",
    "plt.plot(epochs_range, val_losses, label='Val Loss', marker='o')\n",
    "plt.title('Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, train_accuracies, label='Train Accuracy', marker='o')\n",
    "plt.plot(epochs_range, val_accuracies, label='Val Accuracy', marker='o')\n",
    "plt.title('Accuracy per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png', dpi=150)  # saves both plots in one image\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
