{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb3a6cc3",
   "metadata": {},
   "source": [
    "# Auto-encoder\n",
    "\n",
    "In their paper, [Badsha et al.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7144625/) \n",
    "propose a fairly elegant scheme for an auto-encoder for single-cell RNAseq data imputation.\n",
    "\n",
    "\n",
    "![Figure 1A of Badsha et al. 2020](images/autoencoder.png)\n",
    "*Figure 1A of Badsha et al. 2020*\n",
    "\n",
    "In order to reproduce their work, \n",
    "first we are going to implement a simple auto-encoder for the gene expression data. \n",
    "\n",
    "From there we will see how we can adapt the loss function to focus the learning on the signal in the data (rather than the noise, which is the missing data here). \n",
    "\n",
    "Here is their code for inpiration: https://github.com/audreyqyfu/LATE/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645f6fff-2db0-4119-8c39-8c98f40059f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## on google colab, you will have to run the following line:\n",
    "#!pip install pytorch-model-summary\n",
    "#!wget https://github.com/Bjarten/early-stopping-pytorch/raw/refs/heads/main/early_stopping_pytorch/early_stopping.py\n",
    "#!mv early_stopping.py pytorchtools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bc04e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_model_summary as pms \n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from pytorchtools import EarlyStopping\n",
    "\n",
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea4565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import os\n",
    "def usage():\n",
    "    '''return RAM usage in Mb'''\n",
    "    process = psutil.Process(os.getpid())\n",
    "    ram = process.memory_info()[0] / float(2 ** 20)\n",
    "    ram = round(ram, 1)\n",
    "    return ram\n",
    "usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51976bc-368b-4e69-8758-459577c4b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "## on google colab, you will have to run the following line:\n",
    "#!wget https://github.com/sib-swiss/pytorch-practical-training/raw/refs/heads/master/data/single_cell/example.hd5\n",
    "#!wget https://github.com/sib-swiss/pytorch-practical-training/raw/refs/heads/master/data/single_cell/example.cellType.csv\n",
    "# and adapt the cells below to point to the files in the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2dac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fname_input = \"data/single_cell/example.hd5\"\n",
    "orientation = 'cell_row'  # cell_row/gene_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610fff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.read_hdf(fname_input)\n",
    "\n",
    "\n",
    "number_0 = (df_tmp != 0).sum().sum()\n",
    "\n",
    "print(\"shape is {}\".format(df_tmp.shape))\n",
    "print('non-zero count is {}'.format( number_0 ))\n",
    "print('non-zero rate  is {:.3f}'.format(number_0 / df_tmp.size ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b81b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ease the analysis, we also have a cell type label, extracted from \n",
    "# https://github.com/10XGenomics/single-cell-3prime-paper/blob/master/pbmc68k_analysis/68k_pbmc_barcodes_annotation.tsv\n",
    "\n",
    "cell_types = pd.read_csv('data/single_cell/example.cellType.csv' , index_col=0)\n",
    "cell_types.celltype.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996251ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## log10 transformation \n",
    "pseudocount = 1\n",
    "\n",
    "input_df = np.log10( df_tmp.transpose() + pseudocount ).transpose()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3090bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = input_df.shape  # m: n_cells; n: n_genes\n",
    "print('input_matrix: {} cells, {} genes\\n'.format(m, n))\n",
    "\n",
    "print(\"memory usage: {}Mb\".format(usage()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9609fc5e",
   "metadata": {},
   "source": [
    "Let's separate training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5121aafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_fraction = 0.3\n",
    "valid_size = int( m * valid_fraction )\n",
    "train_size = m - valid_size\n",
    "\n",
    "\n",
    "np.random.seed(1884)\n",
    "arr = np.arange(m)\n",
    "np.random.shuffle(arr)\n",
    "\n",
    "X_train = input_df.iloc[ arr[:train_size] , : ].to_numpy()\n",
    "X_valid = input_df.iloc[ arr[train_size:] , : ].to_numpy()\n",
    "\n",
    "print('train: {}'.format(train_size))\n",
    "print('valid: {}'.format(valid_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64972b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_train = list( cell_types.loc[ input_df.index[ arr[:train_size] ] , 'celltype' ] )\n",
    "cell_type_valid = list( cell_types.loc[ input_df.index[ arr[train_size:] ] , 'celltype' ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7ae096",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ids = input_df.columns\n",
    "\n",
    "train_cell_ids = input_df.index[ arr[:train_size] ]\n",
    "valid_cell_ids = input_df.index[ arr[train_size:] ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068dc898",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "print(\"memory usage: {}Mb\".format(usage()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1ff91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pca_valid = PCA().fit( X_valid )\n",
    "x_pca = pca_valid.transform( X_valid )\n",
    "pca_valid.explained_variance_ratio_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed8899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cumsum( pca_valid.explained_variance_ratio_ )[ 100 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660d0cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "tsne.fit( x_pca[:,:100] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8a096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "sns.scatterplot( x = tsne.embedding_[:,0],\n",
    "               y = tsne.embedding_[:,1],\n",
    "               hue = cell_type_valid,ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9c7c05",
   "metadata": {},
   "source": [
    "## build the data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b01276",
   "metadata": {},
   "source": [
    "**exercise:** build the dataLoaders, with a batch size of 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bdc89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "## hint : in an autoencoder X is also the target!\n",
    "\n",
    "# create your dataset\n",
    "train_dataset = ...\n",
    "\n",
    "\n",
    "## creating a dataloader\n",
    "train_dataloader = ...\n",
    "\n",
    "# create your dataset\n",
    "valid_dataset = ...\n",
    "\n",
    "## creating a dataloader\n",
    "valid_dataloader = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55056bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/AE_dataload.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b91ee5",
   "metadata": {},
   "source": [
    "# simple autoencoder\n",
    "\n",
    "## model building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa37e8f9",
   "metadata": {},
   "source": [
    "Here we the original paper which uses only 2 layers for the encoder and decoder so we'll follow this design.\n",
    "\n",
    "Architecture:\n",
    " - encoder: \n",
    "        - layer input size > hidden size\n",
    "        - layer hidden size > latent space size\n",
    " - decoder:\n",
    "        - layer latent space size > hidden size\n",
    "        - layer hidden size > layer input size\n",
    "    \n",
    "\n",
    "layer structure : Dropout > linear > ReLU\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9c5e3b",
   "metadata": {},
   "source": [
    "**exercise:** implement the simple auto-encoder with the following specifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aae7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 949  \n",
    "hidden_dim=[500] \n",
    "latent_dim = 100 \n",
    "[input_dim] + hidden_dim + [latent_dim] + hidden_dim + [input_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b966e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Simple_AutoEncoder(torch.nn.Module):\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988950c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### test your model with this line:\n",
    "print(pms.summary(model, torch.zeros(1,949).to(device), show_input=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b94d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 1 cell = 949 values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e3056e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a91b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/AE_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d61e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### test your model with this line:\n",
    "print(pms.summary(model, torch.zeros(1,949).to(device), show_input=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b25cb1",
   "metadata": {},
   "source": [
    "Our loss at this stage will be the Mean Squared Error between the input and the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f8b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "x, = valid_dataset[:5] ## let's go with a batch of 5 samples\n",
    "\n",
    "mseloss = nn.MSELoss()\n",
    "\n",
    "with torch.no_grad(): ## disables tracking of gradient: prevent accidental training + speeds up computation\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    print( \"input shape:\", x.shape)\n",
    "    print( \"prediction shape:\", pred.shape)\n",
    "    print(\"mean squared error:\", mseloss(pred,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71724a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the lower dimensional view of a data point:\n",
    "model.encode(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17b8032",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d16590",
   "metadata": {},
   "source": [
    "## training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84d7bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer , patience = 10 ,  echo = True , echo_batch = False):\n",
    "    \n",
    "    size = len(dataloader.dataset) # how many batches do we have\n",
    "    model.train() #     Sets the module in training mode.\n",
    "    \n",
    "    for batch, (X,) in enumerate(dataloader): # for each batch\n",
    "        X = X.to(device) # send the data to the GPU or whatever device you use for training\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)              # prediction for the model -> forward pass\n",
    "        loss = loss_fn(pred, X)      # loss function from these prediction        \n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()              # backward propagation \n",
    "        #                            https://ml-cheatsheet.readthedocs.io/en/latest/backpropagation.html\n",
    "        #                            https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html\n",
    "        \n",
    "        optimizer.step()             \n",
    "        optimizer.zero_grad()        # reset the gradients\n",
    "                                     # https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch\n",
    "\n",
    "        if echo_batch:\n",
    "            current =  (batch) * dataloader.batch_size +  len(X)\n",
    "            print(f\"Train loss: {loss.item():>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "    if echo:\n",
    "        print(f\"Train loss: {loss.item():>7f}\")\n",
    "\n",
    "    # return the last batch loss\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92460544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(dataloader, model, loss_fn, echo = True):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval() #     Sets the module in evaluation mode\n",
    "    valid_loss = 0\n",
    "    with torch.no_grad(): ## disables tracking of gradient: prevent accidental training + speeds up computation\n",
    "        for (X,) in dataloader:\n",
    "            X = X.to(device)\n",
    "            pred = model(X)\n",
    "            valid_loss += loss_fn(pred, X).item()  ## accumulating the loss function over the batches\n",
    "            \n",
    "    valid_loss /= num_batches\n",
    "\n",
    "    if echo:\n",
    "        print(f\"Valid Error: {valid_loss:>8f}\")\n",
    "    ## return the average loss / batch\n",
    "    return valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa8a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## preamble -> define the model, the loss function, and the optimizer\n",
    "model = Simple_AutoEncoder(  input_dim = len(gene_ids) , \n",
    "                             hidden_dim=[500] ,\n",
    "                             latent_dim = 50 , \n",
    "                             dropout_fraction = 0.05).to(device)\n",
    "\n",
    "\n",
    "mseloss = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                       lr = 3*10**-4) ## using the learning rate from their code\n",
    "\n",
    "\n",
    "## container to keep the scores across all epochs\n",
    "train_scores = []\n",
    "valid_scores = []\n",
    "\n",
    "\n",
    "# overfitting can be an issue here. \n",
    "# we use the early stopping implemented in https://github.com/Bjarten/early-stopping-pytorch\n",
    "# initialize the early_stopping object. \n",
    "# patience: How long to wait after last time validation loss improved.\n",
    "early_stopping = EarlyStopping(patience=25, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816ba56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## lets do a single round, to learn how long it takes\n",
    "train_scores.append( train(train_dataloader, \n",
    "                           model, \n",
    "                           mseloss, \n",
    "                           optimizer, \n",
    "                           echo = True , echo_batch = True ) )\n",
    "\n",
    "valid_scores.append( valid(valid_dataloader, \n",
    "                           model, \n",
    "                           mseloss , \n",
    "                           echo = True) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epoch = 200\n",
    "\n",
    "\n",
    "\n",
    "for t in range(epoch):\n",
    "    echo = t%10==0\n",
    "    if echo:\n",
    "        print('Epoch',len(train_scores)+1 )    \n",
    "\n",
    "    train_scores.append( train(train_dataloader, \n",
    "                               model, \n",
    "                               mseloss, \n",
    "                               optimizer, \n",
    "                               echo = echo , echo_batch = False ) )\n",
    "\n",
    "    valid_scores.append( valid(valid_dataloader, \n",
    "                               model, \n",
    "                               mseloss , \n",
    "                               echo = echo) )\n",
    "\n",
    "    # early_stopping needs the validation loss to check if it has decresed, \n",
    "    # and if it has, it will make a checkpoint of the current model\n",
    "    early_stopping(valid_scores[-1], model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "        \n",
    "# load the last checkpoint with the best model\n",
    "model.load_state_dict(torch.load('checkpoint.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd31cdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_scores , label = 'train')\n",
    "plt.plot(valid_scores, label = 'validation')\n",
    "plt.axvline(np.argmin(valid_scores), linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04544f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, = valid_dataset[:]\n",
    "valid_encoded = model.encode( x.to(device) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317f739a-28b2-489c-a6c3-c38d3c028030",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7700311",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "tsne.fit( valid_encoded.cpu().numpy() )\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "sns.scatterplot( x = tsne.embedding_[:,0],\n",
    "               y = tsne.embedding_[:,1],\n",
    "               hue = cell_type_valid,ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3941cc19",
   "metadata": {},
   "source": [
    "# from autoencoder to imputer\n",
    "\n",
    "To go from an autoencoder to a imputer, we will switch the loss function to make it focus on the points where we have some data and disregards points were the input data is null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe0050",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[0,1,0,2,0,3],\n",
    "                  [1,1,0,0,0,3]]) # X\n",
    "b = torch.Tensor([[1,2,1,1,1,2],\n",
    "                  [0,2,1,2,1,2]]) # prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7eb06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## basic Squared Error:\n",
    "(a-b)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8231823",
   "metadata": {},
   "outputs": [],
   "source": [
    "a!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac2fcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Squared Error where 0s in the original data are masked:\n",
    "non_zero_mask = (a!=0)\n",
    "(a-b)**2 * non_zero_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b5260",
   "metadata": {},
   "outputs": [],
   "source": [
    "## and to compute a mean, we sum and divide by the number of non-zeros\n",
    "SE = torch.sum((a-b)**2 * non_zero_mask)\n",
    "N0 = torch.sum( non_zero_mask )\n",
    "SE/N0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d1c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskedMeanSquareError(output, target):\n",
    "    non_zero_mask = (target!=0)\n",
    "    SE = torch.sum((output - target)**2 * non_zero_mask)\n",
    "    N0 = torch.sum(non_zero_mask)\n",
    "    return SE/N0\n",
    "maskedMeanSquareError(b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, = valid_dataset[:5]\n",
    "x = x.to(device)\n",
    "pred = model(x)\n",
    "\n",
    "mseloss( pred,x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f055b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "maskedMeanSquareError(pred, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01076e05",
   "metadata": {},
   "source": [
    "### synthetic dataset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9ed760-1c4f-4ff1-bd44-e00a8d9fe057",
   "metadata": {},
   "outputs": [],
   "source": [
    "## on google colab you will have to download \n",
    "#!wget https://github.com/sib-swiss/pytorch-practical-training/raw/refs/heads/master/data/single_cell/example.msk90.hd5\n",
    "\n",
    "## and adapt the following cells to read these files from the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caadedf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## same as the original dataset, but with 90% of 0s\n",
    "fname_input = \"data/single_cell/example.msk90.hd5\"\n",
    "orientation = 'cell_row'  # cell_row/gene_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f50a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.read_hdf(fname_input)\n",
    "\n",
    "number_0 = (df_tmp != 0).sum().sum()\n",
    "\n",
    "print(\"shape is {}\".format(df_tmp.shape))\n",
    "print('non-zero count is {}'.format( number_0 ))\n",
    "print('non-zero rate  is {:.3f}'.format(number_0 / df_tmp.size ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cf5499",
   "metadata": {},
   "outputs": [],
   "source": [
    "## log10 transformation \n",
    "pseudocount = 1\n",
    "\n",
    "input_sparse_df = np.log10( df_tmp.transpose() + pseudocount ).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233b969d",
   "metadata": {},
   "source": [
    "Let's separate training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03de4979",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_fraction = 0.3\n",
    "valid_size = int( m * valid_fraction )\n",
    "train_size = m - valid_size\n",
    "\n",
    "\n",
    "np.random.seed(1884)\n",
    "arr = np.arange(m)\n",
    "np.random.shuffle(arr)\n",
    "\n",
    "X_train = input_sparse_df.iloc[ arr[:train_size] , : ].to_numpy()\n",
    "X_valid = input_sparse_df.iloc[ arr[train_size:] , : ].to_numpy()\n",
    "\n",
    "print('train: {}'.format(train_size))\n",
    "print('valid: {}'.format(valid_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36818cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_train = list( cell_types.loc[ input_sparse_df.index[ arr[:train_size] ] , 'celltype' ] )\n",
    "cell_type_valid = list( cell_types.loc[ input_sparse_df.index[ arr[train_size:] ] , 'celltype' ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1fd757",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ids = input_df.columns\n",
    "\n",
    "train_cell_ids = input_df.index[ arr[:train_size] ]\n",
    "valid_cell_ids = input_df.index[ arr[train_size:] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c52e530",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "print(\"memory usage: {}Mb\".format(usage()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d585562",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pca_valid = PCA().fit( X_valid )\n",
    "x_pca = pca_valid.transform( X_valid )\n",
    "pca_valid.explained_variance_ratio_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765c272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tsne = TSNE(n_components=2)\n",
    "tsne.fit( x_pca[:,:100] )\n",
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "sns.scatterplot( x = tsne.embedding_[:,0],\n",
    "               y = tsne.embedding_[:,1],\n",
    "               hue = cell_type_valid,ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a2b1f6",
   "metadata": {},
   "source": [
    "## build the data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a261311",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12492f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your dataset\n",
    "train_dataset = TensorDataset( torch.Tensor(X_train) ) \n",
    "\n",
    "## creating a dataloader\n",
    "train_dataloader = DataLoader( train_dataset , batch_size = batch_size ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e83baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your dataset\n",
    "valid_dataset = TensorDataset( torch.Tensor(X_valid) ) \n",
    "\n",
    "## creating a dataloader\n",
    "valid_dataloader = DataLoader(valid_dataset , batch_size = batch_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0764fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, = train_dataset[:]\n",
    "torch.sum( x == 0 ) / torch.numel( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de74626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, = valid_dataset[:]\n",
    "torch.sum( x == 0 ) / torch.numel( x )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a724fe",
   "metadata": {},
   "source": [
    "## build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe6dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## preamble -> define the model, the loss function, and the optimizer\n",
    "model = Simple_AutoEncoder(  input_dim = len(gene_ids) , \n",
    "                             hidden_dim=[500] ,\n",
    "                             latent_dim = 100 , \n",
    "                             dropout_fraction = 0.05).to(device)\n",
    "\n",
    "\n",
    "\n",
    "#############################################\n",
    "## Here we specify our custom loss function\n",
    "mseloss = maskedMeanSquareError\n",
    "#############################################\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                       lr = 3*10**-4) ## using the learning rate from their code\n",
    "\n",
    "\n",
    "## container to keep the scores across all epochs\n",
    "train_scores = []\n",
    "valid_scores = []\n",
    "\n",
    "\n",
    "# overfitting can be an issue here. \n",
    "# we use the early stopping implemented in https://github.com/Bjarten/early-stopping-pytorch\n",
    "# initialize the early_stopping object. \n",
    "# patience: How long to wait after last time validation loss improved.\n",
    "early_stopping = EarlyStopping(patience=25, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7110a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## lets do a single round, to learn how long it takes\n",
    "train_scores.append( train(train_dataloader, \n",
    "                           model, \n",
    "                           maskedMeanSquareError, \n",
    "                           optimizer, \n",
    "                           echo = True , echo_batch = True ) )\n",
    "\n",
    "valid_scores.append( valid(valid_dataloader, \n",
    "                           model, \n",
    "                           maskedMeanSquareError , \n",
    "                           echo = True) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aa12bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epoch = 200\n",
    "\n",
    "\n",
    "\n",
    "for t in range(epoch):\n",
    "    echo = t%10==0\n",
    "    if echo:\n",
    "        print('Epoch',len(train_scores)+1 )    \n",
    "\n",
    "    train_scores.append( train(train_dataloader, \n",
    "                               model, \n",
    "                               maskedMeanSquareError, \n",
    "                               optimizer, \n",
    "                               echo = echo , echo_batch = False ) )\n",
    "\n",
    "    valid_scores.append( valid(valid_dataloader, \n",
    "                               model, \n",
    "                               maskedMeanSquareError , \n",
    "                               echo = echo) )\n",
    "\n",
    "    # early_stopping needs the validation loss to check if it has decresed, \n",
    "    # and if it has, it will make a checkpoint of the current model\n",
    "    early_stopping(valid_scores[-1], model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "        \n",
    "# load the last checkpoint with the best model\n",
    "model.load_state_dict(torch.load('checkpoint.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e3b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_scores , label = 'train')\n",
    "plt.plot(valid_scores, label = 'validation')\n",
    "plt.axvline(np.argmin(valid_scores), linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1449adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, = valid_dataset[:]\n",
    "valid_encoded = model.encode( x.to(device) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a193cfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "tsne.fit( valid_encoded.cpu().numpy() )\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "sns.scatterplot( x = tsne.embedding_[:,0],\n",
    "               y = tsne.embedding_[:,1],\n",
    "               hue = cell_type_valid,ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299d98e5",
   "metadata": {},
   "source": [
    "Looks like our masked encoder has retrieved some of the data structure despite the heavy sparsity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb0474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## imputation \n",
    "with torch.no_grad():\n",
    "    x, = train_dataset[:]\n",
    "    train_imputed = model( x.to(device) ).cpu().numpy()\n",
    "    x, = valid_dataset[:]\n",
    "    valid_imputed = model( x.to(device) ).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a35b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ground truth\n",
    "df_truth = pd.read_hdf('data/single_cell/example.hd5')\n",
    "## log10 transformation \n",
    "pseudocount = 1\n",
    "df_truth = np.log10( df_truth.transpose() + pseudocount ).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7360c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_train = np.array( df_truth.loc[ train_cell_ids , : ] )\n",
    "truth_valid = np.array( df_truth.loc[ valid_cell_ids , : ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7db6f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remember, the \"ground truth\" data already had ~67% of missing data, \n",
    "##  we do not want to focus on this for the solution assessment\n",
    "\n",
    "train_NI_mask = ( truth_train != 0 ) & ( X_train != 0 ) # non imputed data\n",
    "train_I_mask = ( truth_train != 0 ) & ( X_train == 0 ) # imputed data with a ground truth\n",
    "\n",
    "valid_NI_mask = ( truth_valid != 0 ) & ( X_valid != 0 ) # non imputed data\n",
    "valid_I_mask = ( truth_valid != 0 ) & ( X_valid == 0 ) # imputed data with a ground truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77568241",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# difference of non imputed in train\n",
    "train_non_imputed_diff = ( train_imputed[ train_NI_mask ] - truth_train[ train_NI_mask ] )\n",
    "# difference of imputed in train\n",
    "train_imputed_diff = ( train_imputed[ train_I_mask ] - truth_train[ train_I_mask ] )\n",
    "\n",
    "# difference of non imputed in valid\n",
    "valid_non_imputed_diff = ( valid_imputed[ valid_NI_mask ] - truth_valid[ valid_NI_mask ] )\n",
    "# difference of imputed in valid\n",
    "valid_imputed_diff = ( valid_imputed[ valid_I_mask ] - truth_valid[ valid_I_mask ] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c71c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sizes = (train_non_imputed_diff.shape[0],\n",
    "         train_imputed_diff.shape[0],\n",
    "         valid_non_imputed_diff.shape[0],\n",
    "         valid_imputed_diff.shape[0])\n",
    "\n",
    "sns.violinplot(x = np.concatenate( [train_non_imputed_diff ,\n",
    "                                    train_imputed_diff , \n",
    "                                    valid_non_imputed_diff, \n",
    "                                    valid_imputed_diff]),\n",
    "            y = ['train']*(sizes[0]+sizes[1]) + ['valid']*(sizes[2]+sizes[3]),\n",
    "            hue = ['non-imputed']*sizes[0] + ['imputed']*sizes[1] + ['non-imputed']*sizes[2] + ['imputed']*sizes[3] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed575173",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('train, non-imputed - absolute error:')\n",
    "V = np.abs(train_non_imputed_diff)\n",
    "print('\\tq0.05: {:.4f} , q0.5: {:.4f} , q0.95: {:.4f}'.format( *(np.quantile(V , [0.05,0.5,0.95])) ))\n",
    "print('train, imputed - absolute error:')\n",
    "V = np.abs(train_imputed_diff)\n",
    "print('\\tq0.05: {:.4f} , q0.5: {:.4f} , q0.95: {:.4f}'.format( *(np.quantile(V , [0.05,0.5,0.95])) ))\n",
    "print('valid, non-imputed - absolute error:')\n",
    "V = np.abs(valid_non_imputed_diff)\n",
    "print('\\tq0.05: {:.4f} , q0.5: {:.4f} , q0.95: {:.4f}'.format( *(np.quantile(V , [0.05,0.5,0.95])) ))\n",
    "print('valid, imputed - absolute error:')\n",
    "V = np.abs(valid_imputed_diff)\n",
    "print('\\tq0.05: {:.4f} , q0.5: {:.4f} , q0.95: {:.4f}'.format( *(np.quantile(V , [0.05,0.5,0.95])) ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
